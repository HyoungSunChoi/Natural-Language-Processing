{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch3. Estimator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbThZ4COYV0m"
      },
      "source": [
        "학습(train) : 정의한 모델 파라미터에 대해 학습한다.\n",
        "\n",
        "평가(evaluate) : 학습한 모델에 대한 성능을 측정한다.\n",
        "\n",
        "예측(Predict) : 모델을 통해 입력값에 대한 예측값을 받는다.\n",
        "\n",
        "배포(Export):사용할 모델을 바이너리 파일로 출력한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAwcNNFihcI_"
      },
      "source": [
        "features : 모델에 적용되는 입력값을 의미한다. 하나의 텐서 자료형 혹은 딕셔너리 자료형이어야 한다.\n",
        "\n",
        "labels : 모델의 정답 라벨값을 의미한다. 하나의 텐서 자료형 혹은 딕셔너리 자료형이어야 한다. 예측과정에서는 라벨이 존재하지 않기 때문에, Estimator 에서 자동으로 이 값이 들어오지 않는다.\n",
        "\n",
        "mode : 현재 모델 함수가 실행된 모드(학습, 검증, 예측)를 의미한다.\n",
        "\n",
        "params : 모델에 적용될 부가적인 하이퍼파라미터 값을 의미한다.딕셔너리 자료형이어야 한다.\n",
        "\n",
        "config : 모델에 적용할 설정값을 의미한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeAAJxuJiObi"
      },
      "source": [
        "# 사용법\n",
        "estimator = tf.estimator.Estimator(model_fn = model_fn, model_dir = ..., configs = ... , params = ...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8l1e5SXhSvw"
      },
      "source": [
        "import os\n",
        "import tensorflow.compat.v1 as tf \n",
        "tf.disable_v2_behavior()\n",
        "from tensorflow.keras import preprocessing\n",
        "\n",
        "samples = ['너 오늘 이뻐 보인다',\n",
        "           '나는 오늘 기분이 더러워',\n",
        "           '끝내주는데, 좋은 일이 있나봐',\n",
        "           '나 좋은 일이 생겼어',\n",
        "           '아 오늘 진짜 짜증나',\n",
        "           '환상적인데, 정말 좋은거 같아']\n",
        "\n",
        "label = [[1],[0], [1], [1], [0], [1]]\n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(samples)\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "EPOCH=100\n",
        "\n",
        "def train_input_fn():\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((sequences, label))\n",
        "  dataset = dataset.repeat(EPOCH)\n",
        "  dataset = dataset.batch(1)\n",
        "  dataset = dataset.shuffle(len(sequences))\n",
        "  iterator = dataset.make_one_shot_iterator()\n",
        "\n",
        "  return iterator.get_next()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxaybywNpsC5"
      },
      "source": [
        "VOCAB_SIZE = len(word_index)+1\n",
        "EMB_SIZE = 128\n",
        "\n",
        "def model_fn(features, labels, mode):\n",
        "  TRAIN = mode == tf.estimator.ModeKeys.TRAIN\n",
        "  EVAL = mode == tf.estimator.ModeKeys.EVAL\n",
        "  PREDICT = mode == tf.estimator.ModeKeys.PREDICT\n",
        "\n",
        "  embed_input = tf.keras.layers.Embedding(VOCAB_SIZE, EMB_SIZE)(features)\n",
        "  embed_input = tf.reduce_mean(embed_input, axis=1)\n",
        "\n",
        "  # 은닉충을 거쳐 하나의 입력 벡터로 만들기\n",
        "  hidden_layer = tf.keras.layers.Dense(128, activation='relu')(embed_input)\n",
        "  output_layer = tf.keras.layers.Dense(1)(hidden_layer)\n",
        "  # 출력값에 시그모이드 함수를 적용하여 0과 1사이의 값으로 만들기\n",
        "  output = tf.nn.sigmoid(output_layer) \n",
        "\n",
        "  loss = tf.losses.mean_squared_error(output, labels)\n",
        "\n",
        "  if TRAIN:\n",
        "    global_step = tf.train.get_global_step()\n",
        "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss, global_step)\n",
        "\n",
        "    return tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        train_op = train_op,\n",
        "        loss = loss\n",
        "        )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nx9icQPRWgYT",
        "outputId": "6962516d-3e5c-48f7-908d-49b5a58c8a77"
      },
      "source": [
        "DATA_OUT_PATH = './data_out/'\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists(DATA_OUT_PATH):\n",
        "  os.makedirs(DATA_OUT_PATH)\n",
        "\n",
        "\n",
        "estimator = tf.estimator.Estimator(model_fn = model_fn, model_dir = DATA_OUT_PATH + 'checkpoint/dnn')\n",
        "estimator.train(train_input_fn)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_model_dir': './data_out/checkpoint/dnn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into ./data_out/checkpoint/dnn/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.25118187, step = 1\n",
            "INFO:tensorflow:global_step/sec: 659.039\n",
            "INFO:tensorflow:loss = 0.0023114025, step = 101 (0.154 sec)\n",
            "INFO:tensorflow:global_step/sec: 991.151\n",
            "INFO:tensorflow:loss = 0.001105216, step = 201 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 873.406\n",
            "INFO:tensorflow:loss = 0.00047436642, step = 301 (0.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.553\n",
            "INFO:tensorflow:loss = 0.00015233908, step = 401 (0.107 sec)\n",
            "INFO:tensorflow:global_step/sec: 955.847\n",
            "INFO:tensorflow:loss = 0.00015157055, step = 501 (0.105 sec)\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 600...\n",
            "INFO:tensorflow:Saving checkpoints for 600 into ./data_out/checkpoint/dnn/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 600...\n",
            "INFO:tensorflow:Loss for final step: 2.945236e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x7fd56735a510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb5YuehZLquT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}