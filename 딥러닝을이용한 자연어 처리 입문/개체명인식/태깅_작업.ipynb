{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "양방향 LSTM을 이용한 품사 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "품사 태깅이 된 문장 개수 : 3914\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 토큰화에 품사 태깅이 된 데이터 받기\n",
    "tagged_sentences = nltk.corpus.treebank.tagged_sents()\n",
    "print(\"품사 태깅이 된 문장 개수 :\", len(tagges_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.']\n",
      "['NNP', 'NNP', ',', 'CD', 'NNS', 'JJ', ',', 'MD', 'VB', 'DT', 'NN', 'IN', 'DT', 'JJ', 'NN', 'NNP', 'CD', '.']\n"
     ]
    }
   ],
   "source": [
    "# 단어와 품사끼리 따로 저장해주기\n",
    "sentences, pos_tags = [], []\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tag_info = zip(*tagged_sentence) # zip으로 동일한 개수를 가지는 시퀀스 자료형에서 동일한 순서로 묶어줌\n",
    "    sentences.append(list(sentence))\n",
    "    pos_tags.append(list(tag_info))\n",
    "    \n",
    "print(sentences[0])\n",
    "print(pos_tags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 최대 길이 : 271\n",
      "샘플 평균 길이 : 25.722023505365357\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"샘플 최대 길이 :\", max(len(l) for l in sentences))\n",
    "print(\"샘플 평균 길이 :\", sum(map(len, sentences))/len(sentences))\n",
    "\n",
    "plt.hist([len(l) for l in sentences], bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(samples):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(samples)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합 크기 : 11388\n",
      "태깅 정보 집합 크기 : 47\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = tokenize(sentences)\n",
    "tar_tokenizer = tokenize(pos_tags)\n",
    "vocab_size = len(src_tokenizer.word_index)+1\n",
    "tag_size = len(tar_tokenizer.word_index)+1\n",
    "\n",
    "print(\"단어 집합 크기 : {}\".format(vocab_size))\n",
    "print(\"태깅 정보 집합 크기 : {}\".format(tag_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩\n",
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 문장의 크기 : (3131, 150)\n",
      "훈련 샘플 레이블의 크기 : (3131, 150)\n",
      "테스트 샘플 문장의 크기 : (783, 150)\n",
      "테스트 샘플 레이블의 크기 : (783, 150)\n"
     ]
    }
   ],
   "source": [
    "# 비율 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model 구축\n",
    "- 태깅은 다대다 문제\n",
    "    - return_sequences = True\n",
    "    - 양방향을 위해 LSTM 을 Bidirectional() 으로 묶어준다\n",
    "- 손실에서 원-핫 인코딩을 하지 않았으면\n",
    "    - sparse_categorical_crossentropy 를 적용해줄 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 12:56:15.482862: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-02 12:56:16.223889: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-02 12:56:16.385097: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-02 12:56:16.941540: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-02 12:56:17.106466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 0.5925 - accuracy: 0.3174"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 12:56:25.773740: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-02 12:56:26.200057: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-02 12:56:26.289757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 14s 404ms/step - loss: 0.5925 - accuracy: 0.3174 - val_loss: 0.3801 - val_accuracy: 0.5405\n",
      "Epoch 2/7\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.2801 - accuracy: 0.6381 - val_loss: 0.2207 - val_accuracy: 0.7121\n",
      "Epoch 3/7\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1903 - accuracy: 0.7427 - val_loss: 0.1754 - val_accuracy: 0.7635\n",
      "Epoch 4/7\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.1521 - accuracy: 0.7893 - val_loss: 0.1510 - val_accuracy: 0.8035\n",
      "Epoch 5/7\n",
      "25/25 [==============================] - 7s 297ms/step - loss: 0.1305 - accuracy: 0.8194 - val_loss: 0.1373 - val_accuracy: 0.8173\n",
      "Epoch 6/7\n",
      "25/25 [==============================] - 7s 296ms/step - loss: 0.1136 - accuracy: 0.8431 - val_loss: 0.1311 - val_accuracy: 0.8270\n",
      "Epoch 7/7\n",
      "25/25 [==============================] - 7s 299ms/step - loss: 0.0988 - accuracy: 0.8631 - val_loss: 0.1277 - val_accuracy: 0.8292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3443b7640>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "embedding_dim = 128\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.01), metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=7, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 2s 57ms/step - loss: 0.1271 - accuracy: 0.8287\n",
      "\n",
      " 테스트 정확도: 0.8287\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 12:57:16.039566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-02 12:57:16.426830: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-02 12:57:16.513654: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어             |실제값  |예측값\n",
      "-----------------------------------\n",
      "since            : IN      IN\n",
      "chalk            : NN      NNP\n",
      "first            : RB      JJ\n",
      "touched          : VBD     NNP\n",
      "slate            : NN      NNS\n",
      ",                : ,       ,\n",
      "schoolchildren   : NN      NNS\n",
      "have             : VBP     VBP\n",
      "wanted           : VBN     VBN\n",
      "*-1              : -NONE-  -NONE-\n",
      "to               : TO      TO\n",
      "know             : VB      VB\n",
      ":                : :       :\n",
      "what             : WP      WP\n",
      "'s               : VBZ     VBZ\n",
      "*t*-2            : -NONE-  -NONE-\n",
      "on               : IN      IN\n",
      "the              : DT      DT\n",
      "test             : NN      NN\n",
      "?                : .       .\n"
     ]
    }
   ],
   "source": [
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_tag = tar_tokenizer.index_word\n",
    "\n",
    "i = 10 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict(np.array([X_test[i]])) # 입력한 테스트용 샘플에 대해서 예측값 y를 리턴\n",
    "y_predicted = np.argmax(y_predicted, axis=-1) # 확률 벡터를 정수 레이블로 변환.\n",
    "\n",
    "print(\"{:15}|{:5}|{}\".format(\"단어\", \"실제값\", \"예측값\"))\n",
    "print(35 * \"-\")\n",
    "\n",
    "for word, tag, pred in zip(X_test[i], y_test[i], y_predicted[0]):\n",
    "    if word != 0: # PAD값은 제외함.\n",
    "        print(\"{:17}: {:7} {}\".format(index_to_word[word], index_to_tag[tag].upper(), index_to_tag[pred].upper()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8459f5eb1ede4b4f9177267bb7d209bb99cbe04fb453024182bbd03c1d314234"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
