{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패딩 (padding)\n",
    "- 자연어 처리를 하다보면 각 문장(또는 문서)은 서로 길이가 다른 경우가 있다.\n",
    "- 기계는 길이가 전부 동일한 문서들에 대해서는 하나의 행렬로 보고, 한꺼번에 처리가 가능하다\n",
    "    - 즉, 병렬 연산을 위해 길이를 동일하게 맞춰주는 작업이 필요할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "preprocessed_sentences = [['barber', 'person'], ['barber', 'good', 'person'], ['barber', 'huge', 'person'],\n",
    "                          ['knew', 'secret'], ['secret', 'kept', 'huge', 'secret'], ['huge', 'secret'], \n",
    "                          ['barber', 'kept', 'word'], ['barber', 'kept', 'word'], ['barber', 'kept', 'secret'], \n",
    "                          ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'], ['barber', 'went', 'huge', 'mountain']]\n",
    "\n",
    "# 단어 집합 만들고, 정수 인코딩 해주기\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 제로 패딩\n",
    "- 자연어 처리에서 기계는 0 을 무시한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이 : 7\n",
      "[[ 1  5  0  0  0  0  0]\n",
      " [ 1  8  5  0  0  0  0]\n",
      " [ 1  3  5  0  0  0  0]\n",
      " [ 9  2  0  0  0  0  0]\n",
      " [ 2  4  3  2  0  0  0]\n",
      " [ 3  2  0  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  2  0  0  0  0]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 1 12  3 13  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# 모두 동일한 길이로 맞춰주기 위해, 이중 가장 긴 길이 계산하여 통일시켜주기\n",
    "max_len = max(len(item) for item in encoded)\n",
    "print(\"최대 길이 :\", max_len)\n",
    "\n",
    "# 모든 문장 길이 통일시켜주기\n",
    "for sentence in encoded:\n",
    "    while len(sentence) < max_len:\n",
    "        sentence.append(0)\n",
    "\n",
    "padded_np = np.array(encoded)\n",
    "print(padded_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 케라스 전처리 도구로 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5], [1, 8, 5], [1, 3, 5], [9, 2], [2, 4, 3, 2], [3, 2], [1, 4, 6], [1, 4, 6], [1, 4, 2], [7, 7, 3, 2, 10, 1, 11], [1, 12, 3, 13]]\n",
      "[[ 0  0  0  0  0  1  5]\n",
      " [ 0  0  0  0  1  8  5]\n",
      " [ 0  0  0  0  1  3  5]\n",
      " [ 0  0  0  0  0  9  2]\n",
      " [ 0  0  0  2  4  3  2]\n",
      " [ 0  0  0  0  0  3  2]\n",
      " [ 0  0  0  0  1  4  6]\n",
      " [ 0  0  0  0  1  4  6]\n",
      " [ 0  0  0  0  1  4  2]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 0  0  0  1 12  3 13]]\n",
      "두 번쨰 버전!\n",
      " [[ 1  5  0  0  0  0  0]\n",
      " [ 1  8  5  0  0  0  0]\n",
      " [ 1  3  5  0  0  0  0]\n",
      " [ 9  2  0  0  0  0  0]\n",
      " [ 2  4  3  2  0  0  0]\n",
      " [ 3  2  0  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  6  0  0  0  0]\n",
      " [ 1  4  2  0  0  0  0]\n",
      " [ 7  7  3  2 10  1 11]\n",
      " [ 1 12  3 13  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "encoded = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "print(encoded)\n",
    "\n",
    "# Numpy 와 다르게 앞에 0 으로 채워준다\n",
    "padded = pad_sequences(encoded)\n",
    "print(padded)\n",
    "\n",
    "# Numpy 와 동일하게 뒤를 0으로 채우고 싶다면?\n",
    "# padding='post' 추가\n",
    "padded_2 = pad_sequences(encoded, padding='post')\n",
    "print(\"두 번쨰 버전!\\n\",padded_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  5  0  0  0]\n",
      " [ 1  8  5  0  0]\n",
      " [ 1  3  5  0  0]\n",
      " [ 9  2  0  0  0]\n",
      " [ 2  4  3  2  0]\n",
      " [ 3  2  0  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  2  0  0]\n",
      " [ 3  2 10  1 11]\n",
      " [ 1 12  3 13  0]]\n",
      "길이 맞출때 뒤에서부터 삭제하고 싶으면?\n",
      "[[ 1  5  0  0  0]\n",
      " [ 1  8  5  0  0]\n",
      " [ 1  3  5  0  0]\n",
      " [ 9  2  0  0  0]\n",
      " [ 2  4  3  2  0]\n",
      " [ 3  2  0  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  6  0  0]\n",
      " [ 1  4  2  0  0]\n",
      " [ 7  7  3  2 10]\n",
      " [ 1 12  3 13  0]]\n"
     ]
    }
   ],
   "source": [
    "# 문장 길이 제한 두기\n",
    "# 길이를 맞출 때 뒤의 단어부터 살려둔다\n",
    "padded_3 = pad_sequences(encoded, padding='post', maxlen=5)\n",
    "print(padded_3)\n",
    "\n",
    "print(\"길이 맞출때 뒤에서부터 삭제하고 싶으면?\")\n",
    "padded_4 = pad_sequences(encoded, maxlen=5, padding='post', truncating='post')\n",
    "print(padded_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  5, 14, 14, 14],\n",
       "       [ 1,  8,  5, 14, 14],\n",
       "       [ 1,  3,  5, 14, 14],\n",
       "       [ 9,  2, 14, 14, 14],\n",
       "       [ 2,  4,  3,  2, 14],\n",
       "       [ 3,  2, 14, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14],\n",
       "       [ 1,  4,  6, 14, 14],\n",
       "       [ 1,  4,  2, 14, 14],\n",
       "       [ 3,  2, 10,  1, 11],\n",
       "       [ 1, 12,  3, 13, 14]], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0 퓨ㅐ딩 말고 다른 숫자로 하고 싶은 경우\n",
    "last_value = len(tokenizer.word_index)+1 # 단어 집합의 크기보다 1 큰 숫자를 사용\n",
    "print(last_value)\n",
    "\n",
    "padded_5 = pad_sequences(encoded, maxlen=5, padding='post', value=last_value)\n",
    "padded_5\n",
    "\n",
    "# 0 이 아닌 가장 마지막 인덱스 +1 -> 여기서는 14 -> 로 채워짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8459f5eb1ede4b4f9177267bb7d209bb99cbe04fb453024182bbd03c1d314234"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
