{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  추천 시스템 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서의 수 : 2382\n"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/data.csv\", filename=\"data.csv\")\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "print('전체 문서의 수 :',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>image_link</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We know that power is shifting: From West to E...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moisés Naím</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.63</td>\n",
       "      <td>The End of Power: From Boardrooms to Battlefie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Following the success of The Accidental Billio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Blake J. Harris</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.94</td>\n",
       "      <td>Console Wars: Sega, Nintendo, and the Battle t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How to tap the power of social software and ne...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Chris Brogan</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.78</td>\n",
       "      <td>Trust Agents: Using the Web to Build Influence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>William J. Bernstein is an American financial ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>William J. Bernstein</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>The Four Pillars of Investing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Amazing book. And I joined Steve Jobs and many...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Akio Morita</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>Made in Japan: Akio Morita and Sony</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                                               Desc  \\\n",
       "0             0  We know that power is shifting: From West to E...   \n",
       "1             1  Following the success of The Accidental Billio...   \n",
       "2             2  How to tap the power of social software and ne...   \n",
       "3             3  William J. Bernstein is an American financial ...   \n",
       "4             4  Amazing book. And I joined Steve Jobs and many...   \n",
       "\n",
       "   Unnamed: 0                author     genre  \\\n",
       "0         0.0           Moisés Naím  Business   \n",
       "1         1.0       Blake J. Harris  Business   \n",
       "2         2.0          Chris Brogan  Business   \n",
       "3         3.0  William J. Bernstein  Business   \n",
       "4         4.0           Akio Morita  Business   \n",
       "\n",
       "                                          image_link  rating  \\\n",
       "0  https://i.gr-assets.com/images/S/compressed.ph...    3.63   \n",
       "1  https://i.gr-assets.com/images/S/compressed.ph...    3.94   \n",
       "2  https://i.gr-assets.com/images/S/compressed.ph...    3.78   \n",
       "3  https://i.gr-assets.com/images/S/compressed.ph...    4.20   \n",
       "4  https://i.gr-assets.com/images/S/compressed.ph...    4.05   \n",
       "\n",
       "                                               title  \n",
       "0  The End of Power: From Boardrooms to Battlefie...  \n",
       "1  Console Wars: Sega, Nintendo, and the Battle t...  \n",
       "2  Trust Agents: Using the Web to Build Influence...  \n",
       "3                      The Four Pillars of Investing  \n",
       "4                Made in Japan: Akio Morita and Sony  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "    \n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['Desc'].apply(_removeNonAscii)\n",
    "df['cleaned'] = df['cleaned'].apply(make_lower_case)\n",
    "df['cleaned'] = df['cleaned'].apply(remove_stop_words)\n",
    "df['cleaned'] = df['cleaned'].apply(remove_punctuation)\n",
    "df['cleaned'] = df['cleaned'].apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서 개수 :  2381\n"
     ]
    }
   ],
   "source": [
    "# NaN 값 제거하기\n",
    "df['cleaned'].replace('', np.nan, inplace=True)\n",
    "df = df[df['cleaned'].notna()]\n",
    "print(\"전체 문서 개수 : \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for word in df['cleaned']:\n",
    "    corpus.append(word.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 사전 훈련된 워드 임베딩 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b've')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\NLP\\Natural-Language-Processing\\딥러닝을이용한 자연어 처리 입문\\워드 임베딩\\9. 문서 벡터를 이용한 추천시스템.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000022?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m KeyedVectors\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000022?line=3'>4</a>\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mGoogleNews-vectors-negative300.bin.gz\u001b[39m\u001b[39m'\u001b[39m \n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000022?line=4'>5</a>\u001b[0m word2vec_model \u001b[39m=\u001b[39m KeyedVectors\u001b[39m.\u001b[39;49mload_word2vec_format(filename, binary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000022?line=6'>7</a>\u001b[0m \u001b[39m#word2vec_model = Word2Vec(vector_size = 300, window=5, min_count = 2, workers = -1)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000022?line=7'>8</a>\u001b[0m word2vec_model\u001b[39m.\u001b[39mbuild_vocab(corpus)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1629\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1581'>1582</a>\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1582'>1583</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_word2vec_format\u001b[39m(\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1583'>1584</a>\u001b[0m         \u001b[39mcls\u001b[39m, fname, fvocab\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m'\u001b[39m, unicode_errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1584'>1585</a>\u001b[0m         limit\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, datatype\u001b[39m=\u001b[39mREAL, no_header\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1585'>1586</a>\u001b[0m     ):\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1586'>1587</a>\u001b[0m     \u001b[39m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1587'>1588</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1588'>1589</a>\u001b[0m \u001b[39m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1626'>1627</a>\u001b[0m \n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1627'>1628</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1628'>1629</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _load_word2vec_format(\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1629'>1630</a>\u001b[0m         \u001b[39mcls\u001b[39;49m, fname, fvocab\u001b[39m=\u001b[39;49mfvocab, binary\u001b[39m=\u001b[39;49mbinary, encoding\u001b[39m=\u001b[39;49mencoding, unicode_errors\u001b[39m=\u001b[39;49municode_errors,\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1630'>1631</a>\u001b[0m         limit\u001b[39m=\u001b[39;49mlimit, datatype\u001b[39m=\u001b[39;49mdatatype, no_header\u001b[39m=\u001b[39;49mno_header,\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1631'>1632</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\site-packages\\gensim\\models\\keyedvectors.py:1965\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1962'>1963</a>\u001b[0m     fin \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mopen(fname, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1963'>1964</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1964'>1965</a>\u001b[0m     header \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mto_unicode(fin\u001b[39m.\u001b[39;49mreadline(), encoding\u001b[39m=\u001b[39mencoding)\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1965'>1966</a>\u001b[0m     vocab_size, vector_size \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m header\u001b[39m.\u001b[39msplit()]  \u001b[39m# throws for invalid file format\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/site-packages/gensim/models/keyedvectors.py?line=1966'>1967</a>\u001b[0m \u001b[39mif\u001b[39;00m limit:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\gzip.py:390\u001b[0m, in \u001b[0;36mGzipFile.readline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=387'>388</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadline\u001b[39m(\u001b[39mself\u001b[39m, size\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=388'>389</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_not_closed()\n\u001b[1;32m--> <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=389'>390</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mreadline(size)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/_compression.py?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[0;32m     <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/_compression.py?line=66'>67</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b) \u001b[39mas\u001b[39;00m view, view\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m byte_view:\n\u001b[1;32m---> <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/_compression.py?line=67'>68</a>\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m(byte_view))\n\u001b[0;32m     <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/_compression.py?line=68'>69</a>\u001b[0m         byte_view[:\u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[0;32m     <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/_compression.py?line=69'>70</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\gzip.py:479\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=474'>475</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_member:\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=475'>476</a>\u001b[0m     \u001b[39m# If the _new_member flag is set, we have to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=476'>477</a>\u001b[0m     \u001b[39m# jump to the next member, if there is one.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=477'>478</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_read()\n\u001b[1;32m--> <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=478'>479</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_gzip_header():\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=479'>480</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pos\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=480'>481</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\nlp\\lib\\gzip.py:427\u001b[0m, in \u001b[0;36m_GzipReader._read_gzip_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=423'>424</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=425'>426</a>\u001b[0m \u001b[39mif\u001b[39;00m magic \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\037\u001b[39;00m\u001b[39m\\213\u001b[39;00m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=426'>427</a>\u001b[0m     \u001b[39mraise\u001b[39;00m BadGzipFile(\u001b[39m'\u001b[39m\u001b[39mNot a gzipped file (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m magic)\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=428'>429</a>\u001b[0m (method, flag,\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=429'>430</a>\u001b[0m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_mtime) \u001b[39m=\u001b[39m struct\u001b[39m.\u001b[39munpack(\u001b[39m\"\u001b[39m\u001b[39m<BBIxx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_exact(\u001b[39m8\u001b[39m))\n\u001b[0;32m    <a href='file:///c%3A/Users/CTLAB/anaconda3/envs/nlp/lib/gzip.py?line=430'>431</a>\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m!=\u001b[39m \u001b[39m8\u001b[39m:\n",
      "\u001b[1;31mBadGzipFile\u001b[0m: Not a gzipped file (b've')"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/mmihaltz/word2vec-GoogleNews-vectors/master/GoogleNews-vectors-negative300.bin.gz\", filename=\"GoogleNews-vectors-negative300.bin.gz\")\n",
    "\n",
    "\n",
    "word2vec_model = Word2Vec(vector_size = 300, window=5, min_count = 2, workers = -1)\n",
    "word2vec_model.build_vocab(corpus)\n",
    "word2vec_model.wv.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz', lockf=1.0, binary=True)\n",
    "word2vec_model.train(corpus, total_examples = word2vec_model.corpus_count, epochs = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_vectors(document_list):\n",
    "    document_embedding_list = []\n",
    "\n",
    "    # 각 문서에 대해서\n",
    "    for line in document_list:\n",
    "        doc2vec = None\n",
    "        count = 0\n",
    "        for word in line.split():\n",
    "            if word in word2vec_model.wv.vocab:\n",
    "                count += 1\n",
    "                # 해당 문서에 있는 모든 단어들의 벡터값을 더한다.\n",
    "                if doc2vec is None:\n",
    "                    doc2vec = word2vec_model[word]\n",
    "                else:\n",
    "                    doc2vec = doc2vec + word2vec_model[word]\n",
    "\n",
    "        if doc2vec is not None:\n",
    "            # 단어 벡터를 모두 더한 벡터의 값을 문서 길이로 나눠준다.\n",
    "            doc2vec = doc2vec / count\n",
    "            document_embedding_list.append(doc2vec)\n",
    "\n",
    "    # 각 문서에 대한 문서 벡터 리스트를 리턴\n",
    "    return document_embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\NLP\\Natural-Language-Processing\\딥러닝을이용한 자연어 처리 입문\\워드 임베딩\\9. 문서 벡터를 이용한 추천시스템.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000020?line=0'>1</a>\u001b[0m document_embedding_list \u001b[39m=\u001b[39m get_document_vectors(df[\u001b[39m'\u001b[39;49m\u001b[39mcleaned\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000020?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m문서 벡터의 수 :\u001b[39m\u001b[39m'\u001b[39m,\u001b[39mlen\u001b[39m(document_embedding_list))\n",
      "\u001b[1;32md:\\NLP\\Natural-Language-Processing\\딥러닝을이용한 자연어 처리 입문\\워드 임베딩\\9. 문서 벡터를 이용한 추천시스템.ipynb Cell 11'\u001b[0m in \u001b[0;36mget_document_vectors\u001b[1;34m(document_list)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000019?line=6'>7</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000019?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m line\u001b[39m.\u001b[39msplit():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000019?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m word \u001b[39min\u001b[39;00m word2vec_model\u001b[39m.\u001b[39mwv\u001b[39m.\u001b[39mvocab:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000019?line=9'>10</a>\u001b[0m         count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NLP/Natural-Language-Processing/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%EC%9E%85%EB%AC%B8/%EC%9B%8C%EB%93%9C%20%EC%9E%84%EB%B2%A0%EB%94%A9/9.%20%EB%AC%B8%EC%84%9C%20%EB%B2%A1%ED%84%B0%EB%A5%BC%20%EC%9D%B4%EC%9A%A9%ED%95%9C%20%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C.ipynb#ch0000019?line=10'>11</a>\u001b[0m         \u001b[39m# 해당 문서에 있는 모든 단어들의 벡터값을 더한다.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word2vec_model' is not defined"
     ]
    }
   ],
   "source": [
    "document_embedding_list = get_document_vectors(df['cleaned'])\n",
    "print('문서 벡터의 수 :',len(document_embedding_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a867a277ecf2af885ec9568148caf8a8507793bb561c75f760acfb1c32ff6b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38_NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
