{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tape_gradient() 는 자동 미분 기능을 수행한다.  \n",
    "$ 임의로 2w^2 +5 $ 라는 식을 세우고 w 에 대하여 미분한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 22:09:14.421935: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-03 22:09:14.422126: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(2.)\n",
    "\n",
    "def f(w):\n",
    "    y = w**2\n",
    "    z = 2*y + 5\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradients 를 출력하면 w에 대해 미분한 값이 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z=f(w)\n",
    "\n",
    "gradients = tape.gradient(z, [w])\n",
    "print(gradients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 자동 미분을 이용한 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 21. 23. 25.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 22:11:18.002646: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-02-03 22:11:18.002796: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# 학습될 가중치 변수를 선언\n",
    "w = tf.Variable(4.)\n",
    "b = tf.Variable(1.)\n",
    "\n",
    "@tf.function\n",
    "def hypothesis(x):\n",
    "    return w*x+b\n",
    "\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 22:15:13.037817: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-03 22:15:13.062276: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-03 22:15:13.251710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-03 22:15:13.296251: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   0 | w의 값 : 8.2133 | b의 값 : 1.664 | cost : 1402.555542\n",
      "epoch :  10 | w의 값 : 10.4971 | b의 값 : 1.977 | cost : 1.351182\n",
      "epoch :  20 | w의 값 : 10.5047 | b의 값 :  1.93 | cost : 1.328165\n",
      "epoch :  30 | w의 값 : 10.5119 | b의 값 : 1.884 | cost : 1.306967\n",
      "epoch :  40 | w의 값 : 10.5188 | b의 값 : 1.841 | cost : 1.287436\n",
      "epoch :  50 | w의 값 : 10.5254 | b의 값 : 1.799 | cost : 1.269459\n",
      "epoch :  60 | w의 값 : 10.5318 | b의 값 : 1.759 | cost : 1.252898\n",
      "epoch :  70 | w의 값 : 10.5379 | b의 값 : 1.721 | cost : 1.237644\n",
      "epoch :  80 | w의 값 : 10.5438 | b의 값 : 1.684 | cost : 1.223598\n",
      "epoch :  90 | w의 값 : 10.5494 | b의 값 : 1.648 | cost : 1.210658\n",
      "epoch : 100 | w의 값 : 10.5548 | b의 값 : 1.614 | cost : 1.198742\n",
      "epoch : 110 | w의 값 : 10.5600 | b의 값 : 1.582 | cost : 1.187767\n",
      "epoch : 120 | w의 값 : 10.5650 | b의 값 :  1.55 | cost : 1.177665\n",
      "epoch : 130 | w의 값 : 10.5697 | b의 값 :  1.52 | cost : 1.168355\n",
      "epoch : 140 | w의 값 : 10.5743 | b의 값 : 1.492 | cost : 1.159782\n",
      "epoch : 150 | w의 값 : 10.5787 | b의 값 : 1.464 | cost : 1.151890\n",
      "epoch : 160 | w의 값 : 10.5829 | b의 값 : 1.437 | cost : 1.144619\n",
      "epoch : 170 | w의 값 : 10.5870 | b의 값 : 1.412 | cost : 1.137924\n",
      "epoch : 180 | w의 값 : 10.5909 | b의 값 : 1.387 | cost : 1.131752\n",
      "epoch : 190 | w의 값 : 10.5946 | b의 값 : 1.364 | cost : 1.126073\n",
      "epoch : 200 | w의 값 : 10.5982 | b의 값 : 1.341 | cost : 1.120844\n",
      "epoch : 210 | w의 값 : 10.6016 | b의 값 :  1.32 | cost : 1.116026\n",
      "epoch : 220 | w의 값 : 10.6049 | b의 값 : 1.299 | cost : 1.111589\n",
      "epoch : 230 | w의 값 : 10.6081 | b의 값 : 1.279 | cost : 1.107504\n",
      "epoch : 240 | w의 값 : 10.6111 | b의 값 :  1.26 | cost : 1.103736\n",
      "epoch : 250 | w의 값 : 10.6140 | b의 값 : 1.242 | cost : 1.100273\n",
      "epoch : 260 | w의 값 : 10.6168 | b의 값 : 1.224 | cost : 1.097082\n",
      "epoch : 270 | w의 값 : 10.6195 | b의 값 : 1.207 | cost : 1.094143\n",
      "epoch : 280 | w의 값 : 10.6221 | b의 값 : 1.191 | cost : 1.091434\n",
      "epoch : 290 | w의 값 : 10.6245 | b의 값 : 1.176 | cost : 1.088940\n",
      "epoch : 300 | w의 값 : 10.6269 | b의 값 : 1.161 | cost : 1.086645\n"
     ]
    }
   ],
   "source": [
    "# 평균 제곱 오차를 손실함수로 정의\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y))\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "y = [11,22,33,44,53,66,77,87, 95]\n",
    "\n",
    "# 옵티마이저는 경사 하강법을 사용하고, 학습률은 0.01 을 사용한다\n",
    "optimizer = tf.optimizers.SGD(0.01)\n",
    "\n",
    "# 약 300번 간 경사 하강법을 수행한다\n",
    "for i in range(301):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 현재 파라미터에 기반한 입력 x 에 대한 예측값을 y_pred\n",
    "        y_pred = hypothesis(x)\n",
    "        \n",
    "        # 평균 제곱 오차율 계산\n",
    "        cost = mse_loss(y_pred, y)\n",
    "    \n",
    "    # 손실 함수에 대한 파라미터의 미분값 계산\n",
    "    gradients = tape.gradient(cost, [w,b])\n",
    "    \n",
    "    # 파라미터 업데이트\n",
    "    optimizer.apply_gradients(zip(gradients, [w,b]))\n",
    "    \n",
    "    if i%10 == 0 :\n",
    "        print(\"epoch : {:3} | w의 값 : {:5.4f} | b의 값 : {:5.4} | cost : {:5.6f}\".format(i, w.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w, b 의 값이 업데이트됨에 따라 cost 가 줄어든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.35479  54.295143 59.608593 64.92204 ]\n"
     ]
    }
   ],
   "source": [
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 케라스로 구현하는 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunny/miniforge3/envs/py38/lib/python3.8/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "2022-02-03 22:18:41.674452: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 3817.3567 - mse: 3817.3567\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 470.7734 - mse: 470.7734\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 59.0003 - mse: 59.0003\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3336 - mse: 8.3336\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.0982 - mse: 2.0982\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3298 - mse: 1.3298\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2341 - mse: 1.2341\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2212 - mse: 1.2212\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2184 - mse: 1.2184\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2170 - mse: 1.2170\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2156 - mse: 1.2156\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2144 - mse: 1.2144\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2131 - mse: 1.2131\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2118 - mse: 1.2118\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2106 - mse: 1.2106\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2094 - mse: 1.2094\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2081 - mse: 1.2081\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2069 - mse: 1.2069\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2057 - mse: 1.2057\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2045 - mse: 1.2045\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2033 - mse: 1.2033\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2022 - mse: 1.2022\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2010 - mse: 1.2010\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1998 - mse: 1.1998\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1987 - mse: 1.1987\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1975 - mse: 1.1975\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1964 - mse: 1.1964\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1953 - mse: 1.1953\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1942 - mse: 1.1942\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1931 - mse: 1.1931\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1920 - mse: 1.1920\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1909 - mse: 1.1909\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1898 - mse: 1.1898\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1888 - mse: 1.1888\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1877 - mse: 1.1877\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1867 - mse: 1.1867\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1856 - mse: 1.1856\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1846 - mse: 1.1846\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1836 - mse: 1.1836\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1826 - mse: 1.1826\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1816 - mse: 1.1816\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1806 - mse: 1.1806\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1796 - mse: 1.1796\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1786 - mse: 1.1786\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1776 - mse: 1.1776\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1766 - mse: 1.1766\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1757 - mse: 1.1757\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1747 - mse: 1.1747\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1738 - mse: 1.1738\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1729 - mse: 1.1729\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1719 - mse: 1.1719\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1710 - mse: 1.1710\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1701 - mse: 1.1701\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1692 - mse: 1.1692\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1683 - mse: 1.1683\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1674 - mse: 1.1674\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1665 - mse: 1.1665\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1657 - mse: 1.1657\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1648 - mse: 1.1648\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1639 - mse: 1.1639\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1631 - mse: 1.1631\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1622 - mse: 1.1622\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1614 - mse: 1.1614\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1606 - mse: 1.1606\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1597 - mse: 1.1597\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1589 - mse: 1.1589\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1581 - mse: 1.1581\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1573 - mse: 1.1573\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1565 - mse: 1.1565\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1557 - mse: 1.1557\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1549 - mse: 1.1549\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1542 - mse: 1.1542\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1534 - mse: 1.1534\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1526 - mse: 1.1526\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1519 - mse: 1.1519\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1511 - mse: 1.1511\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1504 - mse: 1.1504\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1496 - mse: 1.1496\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1489 - mse: 1.1489\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1481 - mse: 1.1481\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1474 - mse: 1.1474\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1467 - mse: 1.1467\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1460 - mse: 1.1460\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1453 - mse: 1.1453\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1446 - mse: 1.1446\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1439 - mse: 1.1439\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1432 - mse: 1.1432\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1425 - mse: 1.1425\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1418 - mse: 1.1418\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1412 - mse: 1.1412\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1405 - mse: 1.1405\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1398 - mse: 1.1398\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1392 - mse: 1.1392\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1385 - mse: 1.1385\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1379 - mse: 1.1379\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1372 - mse: 1.1372\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1366 - mse: 1.1366\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1360 - mse: 1.1360\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1354 - mse: 1.1354\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1347 - mse: 1.1347\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1341 - mse: 1.1341\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1335 - mse: 1.1335\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1329 - mse: 1.1329\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1323 - mse: 1.1323\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1317 - mse: 1.1317\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1311 - mse: 1.1311\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1306 - mse: 1.1306\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1300 - mse: 1.1300\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1294 - mse: 1.1294\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1288 - mse: 1.1288\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1283 - mse: 1.1283\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1277 - mse: 1.1277\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1271 - mse: 1.1271\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1266 - mse: 1.1266\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1260 - mse: 1.1260\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1255 - mse: 1.1255\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1250 - mse: 1.1250\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1244 - mse: 1.1244\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1239 - mse: 1.1239\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1234 - mse: 1.1234\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1229 - mse: 1.1229\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1223 - mse: 1.1223\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1218 - mse: 1.1218\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1213 - mse: 1.1213\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1208 - mse: 1.1208\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1203 - mse: 1.1203\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1198 - mse: 1.1198\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1193 - mse: 1.1193\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1188 - mse: 1.1188\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1184 - mse: 1.1184\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1179 - mse: 1.1179\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1174 - mse: 1.1174\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1169 - mse: 1.1169\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1165 - mse: 1.1165\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1160 - mse: 1.1160\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1155 - mse: 1.1155\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1151 - mse: 1.1151\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1146 - mse: 1.1146\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1142 - mse: 1.1142\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1137 - mse: 1.1137\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1133 - mse: 1.1133\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1129 - mse: 1.1129\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1124 - mse: 1.1124\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1120 - mse: 1.1120\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1116 - mse: 1.1116\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1111 - mse: 1.1111\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1107 - mse: 1.1107\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1103 - mse: 1.1103\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1099 - mse: 1.1099\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1095 - mse: 1.1095\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1091 - mse: 1.1091\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1087 - mse: 1.1087\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1083 - mse: 1.1083\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1079 - mse: 1.1079\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1075 - mse: 1.1075\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1071 - mse: 1.1071\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1067 - mse: 1.1067\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1063 - mse: 1.1063\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1059 - mse: 1.1059\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1056 - mse: 1.1056\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1052 - mse: 1.1052\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1048 - mse: 1.1048\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1044 - mse: 1.1044\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1041 - mse: 1.1041\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1037 - mse: 1.1037\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1034 - mse: 1.1034\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1030 - mse: 1.1030\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1027 - mse: 1.1027\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1023 - mse: 1.1023\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1020 - mse: 1.1020\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1016 - mse: 1.1016\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1013 - mse: 1.1013\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1009 - mse: 1.1009\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1006 - mse: 1.1006\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1003 - mse: 1.1003\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0999 - mse: 1.0999\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0996 - mse: 1.0996\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0993 - mse: 1.0993\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0990 - mse: 1.0990\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0986 - mse: 1.0986\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0983 - mse: 1.0983\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0980 - mse: 1.0980\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0977 - mse: 1.0977\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0974 - mse: 1.0974\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0971 - mse: 1.0971\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0968 - mse: 1.0968\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0965 - mse: 1.0965\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0962 - mse: 1.0962\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0959 - mse: 1.0959\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0956 - mse: 1.0956\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0953 - mse: 1.0953\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0950 - mse: 1.0950\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0947 - mse: 1.0947\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0944 - mse: 1.0944\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0941 - mse: 1.0941\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0938 - mse: 1.0938\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0936 - mse: 1.0936\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0933 - mse: 1.0933\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0930 - mse: 1.0930\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0927 - mse: 1.0927\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0925 - mse: 1.0925\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0922 - mse: 1.0922\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0919 - mse: 1.0919\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0917 - mse: 1.0917\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0914 - mse: 1.0914\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0912 - mse: 1.0912\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0909 - mse: 1.0909\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0906 - mse: 1.0906\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0904 - mse: 1.0904\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0902 - mse: 1.0902\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0899 - mse: 1.0899\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0897 - mse: 1.0897\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0894 - mse: 1.0894\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0892 - mse: 1.0892\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0889 - mse: 1.0889\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0887 - mse: 1.0887\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0885 - mse: 1.0885\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0882 - mse: 1.0882\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0880 - mse: 1.0880\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0878 - mse: 1.0878\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0875 - mse: 1.0875\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0873 - mse: 1.0873\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0871 - mse: 1.0871\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0869 - mse: 1.0869\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0866 - mse: 1.0866\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0864 - mse: 1.0864\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0862 - mse: 1.0862\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0860 - mse: 1.0860\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0858 - mse: 1.0858\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0856 - mse: 1.0856\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0853 - mse: 1.0853\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0851 - mse: 1.0851\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0849 - mse: 1.0849\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0847 - mse: 1.0847\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0845 - mse: 1.0845\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0843 - mse: 1.0843\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0841 - mse: 1.0841\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0839 - mse: 1.0839\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0837 - mse: 1.0837\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0835 - mse: 1.0835\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0833 - mse: 1.0833\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0831 - mse: 1.0831\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0829 - mse: 1.0829\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0828 - mse: 1.0828\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0826 - mse: 1.0826\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0824 - mse: 1.0824\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0822 - mse: 1.0822\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0820 - mse: 1.0820\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0818 - mse: 1.0818\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0817 - mse: 1.0817\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0815 - mse: 1.0815\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0813 - mse: 1.0813\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0811 - mse: 1.0811\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0810 - mse: 1.0810\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0808 - mse: 1.0808\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0806 - mse: 1.0806\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0804 - mse: 1.0804\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0803 - mse: 1.0803\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0801 - mse: 1.0801\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0799 - mse: 1.0799\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0798 - mse: 1.0798\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0796 - mse: 1.0796\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0794 - mse: 1.0794\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0793 - mse: 1.0793\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0791 - mse: 1.0791\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0790 - mse: 1.0790\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0788 - mse: 1.0788\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0787 - mse: 1.0787\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0785 - mse: 1.0785\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0783 - mse: 1.0783\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0782 - mse: 1.0782\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0780 - mse: 1.0780\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0779 - mse: 1.0779\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0778 - mse: 1.0778\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0776 - mse: 1.0776\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0775 - mse: 1.0775\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0773 - mse: 1.0773\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0772 - mse: 1.0772\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0770 - mse: 1.0770\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0769 - mse: 1.0769\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0768 - mse: 1.0768\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0766 - mse: 1.0766\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0765 - mse: 1.0765\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0763 - mse: 1.0763\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0762 - mse: 1.0762\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0761 - mse: 1.0761\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0759 - mse: 1.0759\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0758 - mse: 1.0758\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0757 - mse: 1.0757\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0755 - mse: 1.0755\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0754 - mse: 1.0754\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0753 - mse: 1.0753\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0752 - mse: 1.0752\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0750 - mse: 1.0750\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0749 - mse: 1.0749\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0748 - mse: 1.0748\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0747 - mse: 1.0747\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0745 - mse: 1.0745\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0744 - mse: 1.0744\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0743 - mse: 1.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 22:18:46.564281: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2bf3a0610>,\n",
       " <matplotlib.lines.Line2D at 0x2bf3a0640>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "x = [1,2,3,4,5,6,7,8,9]\n",
    "y = [11,22,33,44,53,66,77,87,95]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "\n",
    "model.fit(x,y,epochs=300)\n",
    "\n",
    "plt.plot(x, model.predict(x), 'b', x, y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[96.84336]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([9.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8459f5eb1ede4b4f9177267bb7d209bb99cbe04fb453024182bbd03c1d314234"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
