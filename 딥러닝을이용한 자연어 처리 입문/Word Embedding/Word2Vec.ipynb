{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "- 원-핫 벡터의 벡터간 유의미한 유사도를 계산할 수 없는 문제를 해결하는 방법\n",
    "    - 한국 - 서울 + 도쿄 = 일본\n",
    "    - 박찬호 - 야구 + 축구 = 호나우두"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 희소 표현(Spare Representation)\n",
    "- 벡터/행렬의 값이 대부분 0으로 표현되는 방법\n",
    "    - 각 단어 벡터간 유의미한 유사성을 표현할 수 없는 단점이 있음\n",
    "    - 대안으로 단어의 의미를 다차원 공간에 벡터화하는 방법 -> 분산 표현(distributed representation)\n",
    "\n",
    "### 2. 분산 표현(Distributed Representation)\n",
    "- '비슷한 문맥에서 등장하는 단어들은 비슷한 의미를 가진다' 라는 가정을 통해 만들어짐\n",
    "    - 강아지 -> 귀엽다/예쁘다/애교 등과 함께 등장하는데, 가설에 따라 벡터화한다면 해당 단어들은 비슷한 벡터값을 가지게 된다.\n",
    "- 위와 같이 표현된 차원이 단어 집합의 크기일 필요가 없으므로, 벡터의 차원이 상대적으로 저차원으로 줄어든다.\n",
    "- 즉, 단어의 의미를 여러 차원에다가 분산하여 표현한다.\n",
    "    - 단어 벡터 간 유의미한 유사도를 계산할 수 있다.\n",
    "\n",
    "### 3. CBOW(Continuous Bag of Words)\n",
    "- Word2Vec의 학습 방식 중 첫 번째\n",
    "- CBOW : 주변에 있는 단어들을 입력으로 중간에 있는 단어들을 예측하는 방법\n",
    "    - \"The fat cat sat on the mat\"\n",
    "    - ['The','fat','cat','on','the','mat'] 으로 'sat'을 예측하는 것\n",
    "    - sat -> 중심 단어 // 배열 -> 주변 단어\n",
    "    - 중심 단어를 예측하기 위해 앞,뒤로 몇 개의 단어를 볼지 결정 : (window)\n",
    "        - 윈도우 크기가 2, 예측하는 단어가 sat 이면 ['fat','cat'], ['on','the'] 를 참고한다.\n",
    "        - 윈도우가 정해지면, 중심 단어를 바꿔가며 학습하는 데이터 셋을 만드는 것 -> 슬라이딩 윈도우\n",
    "<p align='center'><img src= 'https://wikidocs.net/images/page/22660/단어.PNG'></p>   \n",
    "\n",
    "- CBOW 인공신경망 간단하게 도식화\n",
    "    - Word2Vec은 은닉층이 다수인 딥러닝 모델이 아니라, 1개인 얕은 신경망이다.\n",
    "    - Word2Vec의 은닉층은 활성화 함수가 존재하지 않아 Projection Layer 이라고도 한다.    \n",
    "<p align='center'><img src= 'https://wikidocs.net/images/page/22660/word2vec_renew_1.PNG'></p>\n",
    "\n",
    "- Skip-Gram : 중간에 있는 단어들을 입력으로 주변 단어들을 예측하는 방법\n",
    "    - CBOW 보다 성능이 높음\n",
    "<p align='center'><img src='https://wikidocs.net/images/page/22660/word2vec_renew_6.PNG'></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NNLM 보다 학습 속도에서 우위를 가지는 이유는, 은닉층을 제거하였고, 소프트맥스 & 네거티브 샘플링을 하기 때문에 학습속도가 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NNLM : $ (n × m) + (n × m × h) + (h × V) $\n",
    "- Word2Vec : $(n × m) + (m × log(V))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *실습하기*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 영어 Word2Vec 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 훈련 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x14f81da60>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 훈련 데이터 파일은 xml 문법으로 작성되어 있어 자연어를 얻기 위해서는 전처리가 필요\n",
    "    -  <.content>와 <./content> 사이의 내용만 사용\n",
    "    - (Laughter) / (Applause) 와 같은 배경음 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 데이터 전처리 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML)\n",
    "\n",
    "# xml 파일로부터 <content></content> 사이의 내용만 가져오기\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "\n",
    "# 정규 표현식의 sub 모듈로 (Audio),(Laughter) 배경음 부분 제거하기\n",
    "# 괄호로 구성된 내용을 제거해준다.\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화 수행\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "# 각 문장에 대해서 구두점 제거, 대문자를 소문자로 변환\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "    normalized_text.append(tokens)\n",
    "    \n",
    "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 273380\n"
     ]
    }
   ],
   "source": [
    "print(\"총 샘플의 수 : {}\".format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# 샘플 3개만 출력\n",
    "for line in result[:3]:\n",
    "    print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Word2Vec 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- vector_size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
    "- window = 컨텍스트 윈도우 크기\n",
    "- min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
    "- workers = 학습을 위한 프로세스 수\n",
    "- sg = 0은 CBOW, 1은 Skip-gram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec은 입력한 단어에 대해서 가장 유사한 단어를 출력하는 Model.wv.most_similar를 지원해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8426466584205627), ('guy', 0.8124483823776245), ('boy', 0.7683150768280029), ('lady', 0.7669482231140137), ('soldier', 0.7467086911201477), ('girl', 0.7355344295501709), ('gentleman', 0.7196527123451233), ('kid', 0.6867880821228027), ('poet', 0.6823352575302124), ('friend', 0.6650294661521912)]\n"
     ]
    }
   ],
   "source": [
    "# man과 가장 유사한 단어 구하기\n",
    "# 단어 유사도 가져오기\n",
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Word2Vec모델 저장하고 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8426466584205627),\n",
       " ('guy', 0.8124483823776245),\n",
       " ('boy', 0.7683150768280029),\n",
       " ('lady', 0.7669482231140137),\n",
       " ('soldier', 0.7467086911201477),\n",
       " ('girl', 0.7355344295501709),\n",
       " ('gentleman', 0.7196527123451233),\n",
       " ('kid', 0.6867880821228027),\n",
       " ('poet', 0.6823352575302124),\n",
       " ('friend', 0.6650294661521912)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_result = loaded_model.most_similar('man')\n",
    "model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 한국어 Word2Vec 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings.txt', <http.client.HTTPMessage at 0x2caa0b8b0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('ratings.txt')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        200000 non-null  int64 \n",
      " 1   document  199992 non-null  object\n",
      " 2   label     200000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=train_data.dropna(how='any')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/_38j243d5qq977z0w467cxq00000gn/T/ipykernel_86216/637442668.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "# 정규 표현식으로 한글 외 문자 제거해주기\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로  외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는  부터 뉴까지 버릴께 하나도 없음   최고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와   연기가 진짜 개쩔구나   지루할거라고 생각했는데 몰입해서 봤다   그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로  외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는  부터 뉴까지 버릴께 하나도 없음   최고       1\n",
       "3   9251303  와   연기가 진짜 개쩔구나   지루할거라고 생각했는데 몰입해서 봤다   그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화       1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 199992/199992 [07:41<00:00, 433.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# 불용어 정의\n",
    "stopwords = ['의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를',\n",
    "             '으로', '자', '에', '와','한', '하다']\n",
    "\n",
    "# 형태소 분석기 OKT를 사용한 토큰화 작업\n",
    "okt = Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence\n",
    "                                  if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 73\n",
      "리뷰의 평균 길이 :  10.732819312772511\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"리뷰의 최대 길이 :\", max(len(review) for review in tokenized_data))\n",
    "print(\"리뷰의 평균 길이 : \", sum(map(len, tokenized_data))/len(tokenized_data))\n",
    "plt.hist([len(review) for review in tokenized_data], bins=50)\n",
    "plt.xlabel(\"Length of samples\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec 으로 토큰화된 네이버 영화 리뷰 데이터를 학습한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences = tokenized_data, vector_size=100, window=5,\n",
    "                 min_count=5, workers=4, sg=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16386, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 완성된 임베딩 매트릭스의 크기 확인\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('박중훈', 0.8634495139122009), ('안성기', 0.8413627743721008), ('한석규', 0.829960286617279), ('김명민', 0.8234652280807495), ('최민수', 0.8227699995040894), ('크리스찬', 0.8217244744300842), ('이정재', 0.8208061456680298), ('송강호', 0.8183004856109619), ('설경구', 0.8178545832633972), ('류덕환', 0.8124334812164307)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar('최민식'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('슬래셔', 0.8697999715805054), ('무협', 0.8396877646446228), ('느와르', 0.8285381197929382), ('물', 0.8252530097961426), ('무비', 0.8177266716957092), ('호러', 0.8142393231391907), ('물의', 0.7998375296592712), ('블록버스터', 0.7928337454795837), ('홍콩', 0.7923600673675537), ('하이', 0.788041353225708)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(\"히어로\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 사전 훈련된 Word2Vec 임베딩\n",
    "\n",
    "- 방대한 데이터로 사전에 훈련된 워드 임베딩을 사용 할 수 있다.\n",
    "- 예를 들어 감성 분류 작업 시, 훈련 데이터의 양이 부족한 솽황이라면, 다른 방대한 데이터를 Word2Vec 이나 GloVe등으로 사전에 학습시킨 임베딩 벡터를 가지고 모델의 입력으로 사용하여 더 좋은 성능을 가질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import gensim\n",
    "import urllib.request\n",
    "\n",
    "# 구글의 사전 훈련된 Word2Vec 모델을 로드.\n",
    "urllib.request.urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", \\\n",
    "                           filename=\"GoogleNews-vectors-negative300.bin.gz\")\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8459f5eb1ede4b4f9177267bb7d209bb99cbe04fb453024182bbd03c1d314234"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
