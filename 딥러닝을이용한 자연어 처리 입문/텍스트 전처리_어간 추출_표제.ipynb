{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어간 추출(Stemming) & 표제어 추출(Lemmatization)\n",
    "\n",
    "- 코퍼스에 있는 단어 개수 줄이는 방법\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어권 에서의 어간 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 표제어 추출(Lemmatization)\n",
    "    - 기본 사전형 단어\n",
    "    - 단어들로부터 표제어를 찾아가는 과정\n",
    "    - 단어들이 다른 형태를 가지더라도 , 뿌리 단어를 찾아가서 단어의 개수를 줄일 수 있는지를 판단\n",
    "        - e.x) am,are,is 의 뿌리단어는 be이다.  이때, 단어들의 표제어는 be 이다.\n",
    "    - 표제어 추출은 형태학적 파싱을 먼저 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "형태학적 파싱\n",
    "1. 어간(Stem) \n",
    "    - 단어의 의므를 담고 이쓴ㄴ 단어의 핵심 부분\n",
    "2. 접사(affix)\n",
    "    - 단어에 추가적인 의미를 주는 부분\n",
    "위 두 가지 구성 요소를 분리하는 작업\n",
    "- ex) cats -> cat(어간) + -s(접사)\n",
    "- ex) fox 는 독립적인 형태소랄 분리가 되지 않는다    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have','going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print(\"표제어 추출 전 :\", words)\n",
    "print(\"표제어 추출 후 :\", [lemmatizer.lemmatize(word) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표제어 추출 후, dy, ha 와 같이 의미를 알 수 없는 단어를 출력한다.\n",
    "    - 표제어 추출기가 본래 단어의 품사 정보를 알아야만 정확한 결과를 얻을 수 있기 때문이다.\n",
    "    - dies, watched, has가 문장에서 동사로 쓰였던 것을 알려준다면 표제어 추출기는 품사 정보를 보존할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'die'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('dies','v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('watched','v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('has','v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표제어 추출은 문맥을 고려하며 수행했을 때, 해당 단어의 품사 정보를 보존한다.\n",
    "- 그러나 어간 추출을 수행한 결과는 품사 정보가 보존되지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 어간 추출(Stemming)\n",
    "- 형태학적 분석을 단순화한 버전\n",
    "- 정해진 규칙으로 단어의 어미를 자르는 것\n",
    "- 결과로 나오는 단어는 사전에 존재하지 않는 단어일 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 : ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
      "\n",
      "어간 추출 후 : ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "sentence = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--\\\n",
    "    with the single exception of the red crosses and the written notes.\"\n",
    "\n",
    "tokenized_sentence = word_tokenize(sentence)\n",
    "\n",
    "print(\"어간 추출 전 :\", tokenized_sentence)\n",
    "print()\n",
    "print(\"어간 추출 후 :\", [stemmer.stem(word) for word in tokenized_sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ALIZE -> AL\n",
    "- ANCE -> 제거\n",
    "- 실제 사전에 없는 단어들로 바뀌는 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 : ['formalize', 'allowance', 'electricial']\n",
      "어간 추출 후 : ['formal', 'allow', 'electrici']\n"
     ]
    }
   ],
   "source": [
    "words = ['formalize', 'allowance', 'electricial']\n",
    "\n",
    "print('어간 추출 전 :', words)\n",
    "print('어간 추출 후 :', [stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어간 추출 속도는 표제어 추출보다 빠르다.\n",
    "- 포터 어간 추출기는 정밀하게 설계되어 영어에서 자연어 처리때 사용하자\n",
    "- NLTK에서는 포터 알고리즘 외에, 랭커스터 스태머 알고리즘을 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "포터 스테머의 어간 추출 후 : ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
      "랭커스터 스테머의 어간 추출 후 : ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "# 랭커스터 스테머 vs 포터 스테머\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print(\"어간 추출 전 :\", words)\n",
    "print(\"포터 스테머의 어간 추출 후 :\", [porter_stemmer.stem(w) for w in words])\n",
    "print(\"랭커스터 스테머의 어간 추출 후 :\", [lancaster_stemmer.stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "코퍼스에 적용할 때, 어떤 알고리즘이 적합한지 반드시 확인하여 적용할 것\n",
    "\n",
    "- 이런 규칙에 기반한 알고리즘은 일반화를 못하는 경우가 있다. \n",
    "    - 지나치게 일반화가 되거나, 덜되는 경우이다.\n",
    "    - organization -> organ   ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글에서의 어간 추출\n",
    "\n",
    "언    ,,,,,              품사\n",
    "\n",
    "\n",
    "체언 <t> 명사/대명사/수사\n",
    "\n",
    "\n",
    "수식언 <t> 관형사/부사\n",
    "\n",
    "\n",
    "관계언 <t> 조사\n",
    "\n",
    "\n",
    "독립언 <t> 감탄사\n",
    "\n",
    "\n",
    "용언 <t> 동사/형용사\n",
    "\n",
    "- 용언에 해당되는 동사/형용사는 어간(stem)과 어미(ending)의 결합으로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 활용 (conjugation)\n",
    "- 용언의 어간(Stem)이 어미(ending)을 가지는 일을 말한다\n",
    "    - 어간(Stem)\n",
    "        - 용언(동사, 형용사)를 활용할 때 원칙적으로 모양이 변하지 않는 부분, 활용에서 어미에 선행하는 부ㅜㄴ, \n",
    "        - 때로는 어간의 모양도 바뀔 수 있음 (예 : 긋다, 긋고, 그어서, 그어라)\n",
    "    - 어미(ending)\n",
    "        - 용언의 어간 뒤에 붙어서 활용하면서 변하는 부분\n",
    "        - 여러 문법적 기능을 수행\n",
    "- 활용의 방식 2가지\n",
    "    - 어간이 어미를 취할 때, 어간의 모습이 일정하다면 규칙 활용\n",
    "    - 어간이나 어미의 모습이 변하는 불규칙 활용\n",
    "\n",
    "2. 규칙 활용\n",
    "- 어간이 어미를 취할 때, 어간의 모습이 일정하다.\n",
    "- ex) 어간과 어미가 합쳐질 때 어간의 형태가 바뀌지 않음\n",
    "    - 잡/어간 + 다/어미\n",
    "\n",
    "3. 불규칙 활용\n",
    "- 어간이 어미를 취할 때, 어간의 모습이 바뀌거나 취하는 어미가 특수한 어미일 경우\n",
    "- ex) 듣-, 돕-, 곱-, 잇-, 오르-, 노랗- 등이 <br> '듣/들-, 돕/도우-, 곱/고우-, 잇/이-, 올/올-, 노랗/노라- 와 같이 어간의 형식이 달리지거나,<br>\n",
    " 오르+ 아/어 -> 올라 , 하+아/어-> 하여, 이르/아/어 -> 이르러, 푸르+아/어-> 푸르러 와 같이 특수한 어미를 취하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a867a277ecf2af885ec9568148caf8a8507793bb561c75f760acfb1c32ff6b3d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('py38_NLP': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
