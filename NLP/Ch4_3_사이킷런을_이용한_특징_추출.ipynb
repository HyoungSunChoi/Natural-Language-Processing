{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ch4-3. 사이킷런을 이용한 특징 추출.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtnXx6OjsMmv"
      },
      "source": [
        "자연어 처리에서 특징 추출이란, 텍스트 데이터에서 단어나 문장들을 어떤 특징 값으로 바꿔주는 것을 의미한다. \n",
        "- 기존에 문자로 구성되었던 데이터를, 모델에 적용할 수 있도록 특징을 뽑아, 어떤 값으로 바꿔서 수치화한다.\n",
        "\n",
        "#### 벡터를 만드는 방법\n",
        "- CountVectorizer\n",
        "  - 단순히 각 텍스트에서 횟수를 기준으로 특징을 추출하는 방법\n",
        "- TfidfVectorizer\n",
        "  - TF-IDF 을 활용해 텍스트에서 특징을 추출\n",
        "- HashingVectorizer\n",
        "  - CountVectorizer 와 동일한 방법이지만, 텍스트를 처리할 때 해시함수를 사용하여, 실행시간을 줄일 수 있다.\n",
        "  - 텍스트의 크기가 클수록 효율적이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk1O_3Qdshhf"
      },
      "source": [
        "### Count Vectorizer\n",
        "- 문장을 입력으로 받아 단어의 횟수를 측정한 뒤 벡터로 만든다.\n",
        "- 먼저 객체를 생성한다\n",
        "- 객체에 특정 텍스트를 적합시킨다. ( 횟수를 셀 단어의 목록을 만드는 과정\n",
        "- 횟수를 기준으로 해당 텍스트를 벡터화한다.\n",
        "\n",
        "ex.) \n",
        "\n",
        "     \"나는 매일 공부를 한다\" \n",
        "\n",
        "     \"나는 너가 매일 공부를 한다 좋아한다 -> \"1, 0, 1, 1, 1, 0\" 으로 전환\n",
        "\n",
        "     \"나는 매일 매일 공부를 한다  -> \"1, 0, 2, 1, 1, 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuKvUFB3txkU"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjartpr7wfc9",
        "outputId": "62bace2c-c567-4316-97d4-e6e408d985f8"
      },
      "source": [
        "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
        "count_vectorizer =CountVectorizer()\n",
        "\n",
        "# 단어 사전 만들기\n",
        "count_vectorizer.fit(text_data)\n",
        "print(count_vectorizer.vocabulary_)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR7vlZZLwzgr",
        "outputId": "cfc0e280-9e14-477d-8238-26a530937cad"
      },
      "source": [
        "sentence = [text_data[0]] # ['나는 배가 고프다']\n",
        "print(count_vectorizer.transform(sentence).toarray())\n",
        "# 나는 배가 고프다를 딕셔너리화"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0 1 0 0 0 1 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "310WMKlsw8yi"
      },
      "source": [
        "### TfidfVecotorizer\n",
        "TF(Term Frequency)란 특정 단어가 하나의 데이터 안에서 등장하는 횟수를 의미한다.\n",
        "\n",
        "DF(Document Frequency)는 문서의 빈도 값으로, 특정 단어가 여러 데이터에 자주 등장하는지를 알려주는 지표다.\n",
        "\n",
        "IDF(Inverse Document Frequency) 는 이 값에 역수를 취하여 구할 수 있으며, 특정 단어가 다른 데이터에 등장하지 않을수록 값이 커지는것을 의미한다.\n",
        "\n",
        "즉 TF-IDF는 위 2 값을 곱해서 사용하므로, \"어떤 단어가 해당 문서에 자주 등장하지만, 다른 문서에는 많이 없는 단어일수록 높은 값을 가지게 된다.\"\n",
        "  - 조사나 지시대명사처럼 자주 등장하는 단어는 TF값은 크지만 IDF 값은 작아지므로 CountVectorizer의 문제점을 해결해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAmzh6UXXlpS",
        "outputId": "ba3fc64b-ae8f-4a66-add7-3f3c99630dab"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "text_data = ['나는 배가 고프다', '내일 점심 뭐먹지', '내일 공부 해야겠다', '점심 먹고 공부 해야지']\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vectorizer.fit(text_data)\n",
        "print(tfidf_vectorizer.vocabulary_)\n",
        "\n",
        "# 점심 먹고 공부해야지 에 대한 변환\n",
        "sentence = [text_data[3]]\n",
        "print(tfidf_vectorizer.transform(sentence).toarray())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
            "[[0.         0.43779123 0.         0.         0.55528266 0.\n",
            "  0.         0.43779123 0.         0.55528266]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLpc_1zIfjEJ"
      },
      "source": [
        "|"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}